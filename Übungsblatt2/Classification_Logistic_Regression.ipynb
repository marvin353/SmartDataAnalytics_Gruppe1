{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Classification: Klassische Methoden\n",
    "## Logistische Regression\n",
    "In diesem Notebook versuchen wir die Klassifizierung in \"Failure\" / \"No Failure\" mit logistischer Regression durchzuführen."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import Preprocessing as pp\n",
    "from sklearn.metrics import classification_report\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "path_data = '/Users/marvinwoller/Desktop/SmartDataAnalytics/Blatt2/data/'\n",
    "\n",
    "rootdir_train = path_data + 'train/'\n",
    "rootdir_test = path_data + 'test/'\n",
    "\n",
    "train_labels_path = path_data + 'train_label.csv'\n",
    "test_labels_path = path_data + 'test_label.csv'\n",
    "\n",
    "feature_path = path_data + 'features/'\n",
    "feature_path_test = path_data + 'features_test/'\n",
    "\n",
    "resampled_path = path_data + 'resampled/'\n",
    "resampled_path_test = path_data + 'resampled_test/'\n",
    "\n",
    "train_labels = pd.read_csv(train_labels_path, index_col=0) #Don't use index numbers per row but CSV file name as index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classification: Logitisches Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def logreg_classification(X_train,y_train,X_test,y_test,name):\n",
    "    # Split train data to get a second test set without concept drift\n",
    "    X_train, X_test_trainset, y_train, y_test_trainset = train_test_split(X_train, y_train, test_size=0.2, random_state=123)\n",
    "    # Create the classifier\n",
    "    clf = BaggingClassifier(base_estimator=LogisticRegression(), n_estimators=25, random_state=0, n_jobs=-1)\n",
    "    # Fit the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Perform prediction on 20% train set data (no drift)\n",
    "    y_pred_trainset = clf.predict(X_test_trainset)\n",
    "    # Perform prediction on test data (with drift)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"##################### \" + name + \" #####################\")\n",
    "    print(\"---------------- TRAIN ----------------\")\n",
    "    print(\"TRAIN Accuracy (\" + name + \"):\",metrics.accuracy_score(y_test_trainset, y_pred_trainset))\n",
    "    print(classification_report(y_test_trainset, y_pred_trainset))\n",
    "    print(\"---------------- TEST ----------------\")\n",
    "    print(\"TEST Accuracy (\" + name + \"):\",metrics.accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Input data: Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Use extracted Features for classification\n",
    "features = ['mean', 'median', 'min', 'max', 'std', 'var']\n",
    "features2 = ['std', 'var']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################### mean #####################\n",
      "---------------- TRAIN ----------------\n",
      "TRAIN Accuracy (mean): 0.6745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.73      0.70      1048\n",
      "         1.0       0.67      0.61      0.64       952\n",
      "\n",
      "    accuracy                           0.67      2000\n",
      "   macro avg       0.67      0.67      0.67      2000\n",
      "weighted avg       0.67      0.67      0.67      2000\n",
      "\n",
      "---------------- TEST ----------------\n",
      "TEST Accuracy (mean): 0.5102149819735612\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      1.00      0.67      7582\n",
      "         1.0       0.84      0.01      0.02      7396\n",
      "\n",
      "    accuracy                           0.51     14978\n",
      "   macro avg       0.67      0.50      0.35     14978\n",
      "weighted avg       0.67      0.51      0.35     14978\n",
      "\n",
      "##################### median #####################\n",
      "---------------- TRAIN ----------------\n",
      "TRAIN Accuracy (median): 0.6815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.74      0.71      1048\n",
      "         1.0       0.68      0.62      0.65       952\n",
      "\n",
      "    accuracy                           0.68      2000\n",
      "   macro avg       0.68      0.68      0.68      2000\n",
      "weighted avg       0.68      0.68      0.68      2000\n",
      "\n",
      "---------------- TEST ----------------\n",
      "TEST Accuracy (median): 0.5097476298571237\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      1.00      0.67      7582\n",
      "         1.0       0.72      0.01      0.02      7396\n",
      "\n",
      "    accuracy                           0.51     14978\n",
      "   macro avg       0.62      0.50      0.35     14978\n",
      "weighted avg       0.61      0.51      0.35     14978\n",
      "\n",
      "##################### min #####################\n",
      "---------------- TRAIN ----------------\n",
      "TRAIN Accuracy (min): 0.653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.77      0.70      1048\n",
      "           1       0.68      0.52      0.59       952\n",
      "\n",
      "    accuracy                           0.65      2000\n",
      "   macro avg       0.66      0.65      0.64      2000\n",
      "weighted avg       0.66      0.65      0.65      2000\n",
      "\n",
      "---------------- TEST ----------------\n",
      "TEST Accuracy (min): 0.5108158632661236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      1.00      0.67      7582\n",
      "         1.0       1.00      0.01      0.02      7396\n",
      "\n",
      "    accuracy                           0.51     14978\n",
      "   macro avg       0.75      0.50      0.35     14978\n",
      "weighted avg       0.75      0.51      0.35     14978\n",
      "\n",
      "##################### max #####################\n",
      "---------------- TRAIN ----------------\n",
      "TRAIN Accuracy (max): 0.68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71      1048\n",
      "           1       0.68      0.62      0.65       952\n",
      "\n",
      "    accuracy                           0.68      2000\n",
      "   macro avg       0.68      0.68      0.68      2000\n",
      "weighted avg       0.68      0.68      0.68      2000\n",
      "\n",
      "---------------- TEST ----------------\n",
      "TEST Accuracy (max): 0.5110829216183737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      1.00      0.67      7582\n",
      "         1.0       1.00      0.01      0.02      7396\n",
      "\n",
      "    accuracy                           0.51     14978\n",
      "   macro avg       0.75      0.50      0.35     14978\n",
      "weighted avg       0.75      0.51      0.35     14978\n",
      "\n",
      "##################### std #####################\n",
      "---------------- TRAIN ----------------\n",
      "TRAIN Accuracy (std): 0.582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60      1048\n",
      "           1       0.56      0.56      0.56       952\n",
      "\n",
      "    accuracy                           0.58      2000\n",
      "   macro avg       0.58      0.58      0.58      2000\n",
      "weighted avg       0.58      0.58      0.58      2000\n",
      "\n",
      "---------------- TEST ----------------\n",
      "TEST Accuracy (std): 0.5106155695019362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.75      0.61      7582\n",
      "         1.0       0.51      0.26      0.34      7396\n",
      "\n",
      "    accuracy                           0.51     14978\n",
      "   macro avg       0.51      0.51      0.48     14978\n",
      "weighted avg       0.51      0.51      0.48     14978\n",
      "\n",
      "##################### var #####################\n",
      "---------------- TRAIN ----------------\n",
      "TRAIN Accuracy (var): 0.5635\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.66      0.61      1048\n",
      "           1       0.55      0.46      0.50       952\n",
      "\n",
      "    accuracy                           0.56      2000\n",
      "   macro avg       0.56      0.56      0.56      2000\n",
      "weighted avg       0.56      0.56      0.56      2000\n",
      "\n",
      "---------------- TEST ----------------\n",
      "TEST Accuracy (var): 0.5208973160635599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.80      0.63      7582\n",
      "         1.0       0.53      0.23      0.32      7396\n",
      "\n",
      "    accuracy                           0.52     14978\n",
      "   macro avg       0.53      0.52      0.48     14978\n",
      "weighted avg       0.53      0.52      0.48     14978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: Remove strong drift + scaling\n",
    "for feature in features:\n",
    "    df = pd.read_csv(feature_path + feature + '.csv', index_col=0)\n",
    "    df_test = pd.read_csv(feature_path_test + feature + '.csv', index_col=0)\n",
    "    y_train, X_train = pp.preprocess(df, random_n=10000)\n",
    "    y_test, X_test = pp.preprocess_test(df_test)\n",
    "    logreg_classification(X_train,y_train,X_test,y_test,feature)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################### mean #####################\n",
      "---------------- TRAIN ----------------\n",
      "TRAIN Accuracy (mean): 0.636\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.70      0.67      1048\n",
      "         1.0       0.63      0.57      0.60       952\n",
      "\n",
      "    accuracy                           0.64      2000\n",
      "   macro avg       0.64      0.63      0.63      2000\n",
      "weighted avg       0.64      0.64      0.63      2000\n",
      "\n",
      "---------------- TEST ----------------\n",
      "TEST Accuracy (mean): 0.512217919615436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      1.00      0.67      7582\n",
      "         1.0       1.00      0.01      0.02      7396\n",
      "\n",
      "    accuracy                           0.51     14978\n",
      "   macro avg       0.75      0.51      0.35     14978\n",
      "weighted avg       0.75      0.51      0.35     14978\n",
      "\n",
      "##################### median #####################\n",
      "---------------- TRAIN ----------------\n",
      "TRAIN Accuracy (median): 0.634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.70      0.67      1048\n",
      "         1.0       0.63      0.56      0.59       952\n",
      "\n",
      "    accuracy                           0.63      2000\n",
      "   macro avg       0.63      0.63      0.63      2000\n",
      "weighted avg       0.63      0.63      0.63      2000\n",
      "\n",
      "---------------- TEST ----------------\n",
      "TEST Accuracy (median): 0.5123514487915609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      1.00      0.67      7582\n",
      "         1.0       1.00      0.01      0.02      7396\n",
      "\n",
      "    accuracy                           0.51     14978\n",
      "   macro avg       0.75      0.51      0.35     14978\n",
      "weighted avg       0.75      0.51      0.35     14978\n",
      "\n",
      "##################### min #####################\n",
      "---------------- TRAIN ----------------\n",
      "TRAIN Accuracy (min): 0.637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.75      0.69      1048\n",
      "           1       0.65      0.51      0.57       952\n",
      "\n",
      "    accuracy                           0.64      2000\n",
      "   macro avg       0.64      0.63      0.63      2000\n",
      "weighted avg       0.64      0.64      0.63      2000\n",
      "\n",
      "---------------- TEST ----------------\n",
      "TEST Accuracy (min): 0.5111496862064361\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      1.00      0.67      7582\n",
      "         1.0       1.00      0.01      0.02      7396\n",
      "\n",
      "    accuracy                           0.51     14978\n",
      "   macro avg       0.75      0.51      0.35     14978\n",
      "weighted avg       0.75      0.51      0.35     14978\n",
      "\n",
      "##################### max #####################\n",
      "---------------- TRAIN ----------------\n",
      "TRAIN Accuracy (max): 0.642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.71      0.68      1048\n",
      "           1       0.64      0.57      0.60       952\n",
      "\n",
      "    accuracy                           0.64      2000\n",
      "   macro avg       0.64      0.64      0.64      2000\n",
      "weighted avg       0.64      0.64      0.64      2000\n",
      "\n",
      "---------------- TEST ----------------\n",
      "TEST Accuracy (max): 0.511817332087061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      1.00      0.67      7582\n",
      "         1.0       1.00      0.01      0.02      7396\n",
      "\n",
      "    accuracy                           0.51     14978\n",
      "   macro avg       0.75      0.51      0.35     14978\n",
      "weighted avg       0.75      0.51      0.35     14978\n",
      "\n",
      "##################### std #####################\n",
      "---------------- TRAIN ----------------\n",
      "TRAIN Accuracy (std): 0.5525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.63      0.60      1048\n",
      "           1       0.53      0.47      0.50       952\n",
      "\n",
      "    accuracy                           0.55      2000\n",
      "   macro avg       0.55      0.55      0.55      2000\n",
      "weighted avg       0.55      0.55      0.55      2000\n",
      "\n",
      "---------------- TEST ----------------\n",
      "TEST Accuracy (std): 0.5141540926692483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.88      0.65      7582\n",
      "         1.0       0.53      0.14      0.22      7396\n",
      "\n",
      "    accuracy                           0.51     14978\n",
      "   macro avg       0.52      0.51      0.43     14978\n",
      "weighted avg       0.52      0.51      0.44     14978\n",
      "\n",
      "##################### var #####################\n",
      "---------------- TRAIN ----------------\n",
      "TRAIN Accuracy (var): 0.5515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.71      0.62      1048\n",
      "           1       0.54      0.38      0.45       952\n",
      "\n",
      "    accuracy                           0.55      2000\n",
      "   macro avg       0.55      0.54      0.53      2000\n",
      "weighted avg       0.55      0.55      0.54      2000\n",
      "\n",
      "---------------- TEST ----------------\n",
      "TEST Accuracy (var): 0.523768193350247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.84      0.64      7582\n",
      "         1.0       0.55      0.19      0.29      7396\n",
      "\n",
      "    accuracy                           0.52     14978\n",
      "   macro avg       0.53      0.52      0.46     14978\n",
      "weighted avg       0.53      0.52      0.47     14978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try with different preprocessing (\"good_sensors\" + remove strong drift + scaling)\n",
    "for feature in features:\n",
    "    df = pd.read_csv(feature_path + feature + '.csv', index_col=0)\n",
    "    df_test = pd.read_csv(feature_path_test + feature + '.csv', index_col=0)\n",
    "    y_train, X_train = pp.preprocess(df, random_n=10000, get_good=True)\n",
    "    y_test, X_test = pp.preprocess_test(df_test, get_good=True)\n",
    "    logreg_classification(X_train,y_train,X_test,y_test,feature)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "##################### mean #####################\n",
      "---------------- TRAIN ----------------\n",
      "TRAIN Accuracy (mean): 0.666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.70      0.69      1048\n",
      "         1.0       0.65      0.63      0.64       952\n",
      "\n",
      "    accuracy                           0.67      2000\n",
      "   macro avg       0.67      0.66      0.66      2000\n",
      "weighted avg       0.67      0.67      0.67      2000\n",
      "\n",
      "---------------- TEST ----------------\n",
      "TEST Accuracy (mean): 0.5150887969021232\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.23      0.32      7582\n",
      "         1.0       0.51      0.81      0.62      7396\n",
      "\n",
      "    accuracy                           0.52     14978\n",
      "   macro avg       0.53      0.52      0.47     14978\n",
      "weighted avg       0.53      0.52      0.47     14978\n",
      "\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "##################### median #####################\n",
      "---------------- TRAIN ----------------\n",
      "TRAIN Accuracy (median): 0.6695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.70      0.69      1048\n",
      "         1.0       0.66      0.64      0.65       952\n",
      "\n",
      "    accuracy                           0.67      2000\n",
      "   macro avg       0.67      0.67      0.67      2000\n",
      "weighted avg       0.67      0.67      0.67      2000\n",
      "\n",
      "---------------- TEST ----------------\n",
      "TEST Accuracy (median): 0.5180932033649353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.31      0.40      7582\n",
      "         1.0       0.51      0.73      0.60      7396\n",
      "\n",
      "    accuracy                           0.52     14978\n",
      "   macro avg       0.52      0.52      0.50     14978\n",
      "weighted avg       0.53      0.52      0.50     14978\n",
      "\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "##################### min #####################\n",
      "---------------- TRAIN ----------------\n",
      "TRAIN Accuracy (min): 0.6455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.69      1048\n",
      "           1       0.65      0.54      0.59       952\n",
      "\n",
      "    accuracy                           0.65      2000\n",
      "   macro avg       0.65      0.64      0.64      2000\n",
      "weighted avg       0.65      0.65      0.64      2000\n",
      "\n",
      "---------------- TEST ----------------\n",
      "TEST Accuracy (min): 0.5181599679529977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.91      0.66      7582\n",
      "         1.0       0.56      0.11      0.19      7396\n",
      "\n",
      "    accuracy                           0.52     14978\n",
      "   macro avg       0.54      0.51      0.42     14978\n",
      "weighted avg       0.54      0.52      0.43     14978\n",
      "\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "##################### max #####################\n",
      "---------------- TRAIN ----------------\n",
      "TRAIN Accuracy (max): 0.6645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.68      1048\n",
      "           1       0.65      0.63      0.64       952\n",
      "\n",
      "    accuracy                           0.66      2000\n",
      "   macro avg       0.66      0.66      0.66      2000\n",
      "weighted avg       0.66      0.66      0.66      2000\n",
      "\n",
      "---------------- TEST ----------------\n",
      "TEST Accuracy (max): 0.4983976498865002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.74      0.60      7582\n",
      "         1.0       0.48      0.25      0.33      7396\n",
      "\n",
      "    accuracy                           0.50     14978\n",
      "   macro avg       0.49      0.50      0.46     14978\n",
      "weighted avg       0.49      0.50      0.47     14978\n",
      "\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "##################### std #####################\n",
      "---------------- TRAIN ----------------\n",
      "TRAIN Accuracy (std): 0.575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.60      0.60      1048\n",
      "           1       0.55      0.55      0.55       952\n",
      "\n",
      "    accuracy                           0.57      2000\n",
      "   macro avg       0.57      0.57      0.57      2000\n",
      "weighted avg       0.57      0.57      0.57      2000\n",
      "\n",
      "---------------- TEST ----------------\n",
      "TEST Accuracy (std): 0.5096141006809988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.75      0.61      7582\n",
      "         1.0       0.51      0.26      0.35      7396\n",
      "\n",
      "    accuracy                           0.51     14978\n",
      "   macro avg       0.51      0.51      0.48     14978\n",
      "weighted avg       0.51      0.51      0.48     14978\n",
      "\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "KeyError skipping...\n",
      "##################### var #####################\n",
      "---------------- TRAIN ----------------\n",
      "TRAIN Accuracy (var): 0.562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.67      0.61      1048\n",
      "           1       0.55      0.45      0.49       952\n",
      "\n",
      "    accuracy                           0.56      2000\n",
      "   macro avg       0.56      0.56      0.55      2000\n",
      "weighted avg       0.56      0.56      0.56      2000\n",
      "\n",
      "---------------- TEST ----------------\n",
      "TEST Accuracy (var): 0.5200293764187475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.81      0.63      7582\n",
      "         1.0       0.53      0.22      0.31      7396\n",
      "\n",
      "    accuracy                           0.52     14978\n",
      "   macro avg       0.53      0.52      0.47     14978\n",
      "weighted avg       0.52      0.52      0.47     14978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try with different preprocessing (remove correlation + remove strong drift)\n",
    "for feature in features:\n",
    "    df = pd.read_csv(feature_path + feature + '.csv', index_col=0)\n",
    "    df_test = pd.read_csv(feature_path_test + feature + '.csv', index_col=0)\n",
    "    y_train, X_train = pp.preprocess(df, random_n=10000,rem_corr=True)\n",
    "    y_test, X_test = pp.preprocess_test(df_test, rem_corr=True)\n",
    "    logreg_classification(X_train,y_train,X_test,y_test,feature)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ergebnis\n",
    "Mit logistischer Regression können keine besseren Werte erzielt werden als mit der SVM."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}