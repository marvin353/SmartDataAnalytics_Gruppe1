{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.data import loadlocal_mnist\r\n",
    "\r\n",
    "# Imports for a keras tensorflow model\r\n",
    "from sklearn.preprocessing import LabelBinarizer\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\r\n",
    "from tensorflow.keras.optimizers import SGD\r\n",
    "from tensorflow.keras.datasets import mnist\r\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variabeln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\r\n",
    "batch_size = 128\r\n",
    "sgd = SGD(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] accessing MNIST...\n"
     ]
    }
   ],
   "source": [
    "# Grab the MNIST dataset, it has already training and testing data\r\n",
    "print(\"[INFO] accessing MNIST...\")\r\n",
    "((trainX, trainY), (testX, testY)) = mnist.load_data()\r\n",
    "\r\n",
    "# Each image in the MNIST dataset is represented as a 28x28x1, this needs to be flattened to be used by the ffnn\r\n",
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\r\n",
    "testX = testX.reshape((testX.shape[0], 28, 28, 1))\r\n",
    "\r\n",
    "# Scale data to the range of [0, 1]\r\n",
    "trainX = trainX.astype(\"float32\") / 255.0\r\n",
    "testX = testX.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000,)\n",
      "(10000, 28, 28, 1)\n",
      "(10000,)\n",
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\r\n",
    "print(trainY.shape)\r\n",
    "print(testX.shape)\r\n",
    "print(testY.shape)\r\n",
    "\r\n",
    "print(trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# One-hot-encoding\r\n",
    "# convert the labels from integers to vectors\r\n",
    "lb = LabelBinarizer()\r\n",
    "trainY = lb.fit_transform(trainY)\r\n",
    "testY = lb.transform(testY)\r\n",
    "\r\n",
    "print(trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_functions = [\"relu\",\"sigmoid\",\"tanh\", \"softplus\", \"softsign\", \"selu\", \"elu\"] \r\n",
    "# softmax and exponential activation functions are not working in this setup therefore they are not included in this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with relu as activation function\n",
      "Building model with sigmoid as activation function\n",
      "Building model with tanh as activation function\n",
      "Building model with softplus as activation function\n",
      "Building model with softsign as activation function\n",
      "Building model with selu as activation function\n",
      "Building model with elu as activation function\n"
     ]
    }
   ],
   "source": [
    "# define the cnn (Conv, Conv, Flatten, Output) with the different activations using Keras\r\n",
    "models = []\r\n",
    "for ac in activation_functions:\r\n",
    "    print(f\"Building model with {ac} as activation function\")\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Conv2D(64, kernel_size=3, activation=ac, input_shape=(28,28,1)))\r\n",
    "    model.add(Conv2D(32, kernel_size=3, activation=ac))\r\n",
    "    model.add(Flatten())\r\n",
    "    model.add(Dense(10, activation=\"softmax\"))\r\n",
    "    models.append((model, ac, _))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training networks...\n",
      "\n",
      "[Info] activation = 'relu'\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 29s 62ms/step - loss: 0.7720 - accuracy: 0.7952 - val_loss: 0.3187 - val_accuracy: 0.9095\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 29s 61ms/step - loss: 0.3337 - accuracy: 0.9032 - val_loss: 0.2954 - val_accuracy: 0.9161\n",
      "Epoch 3/20\n",
      "358/469 [=====================>........] - ETA: 6s - loss: 0.3107 - accuracy: 0.9112"
     ]
    }
   ],
   "source": [
    "# Train with SGD, Gradient descent (with momentum) optimizer\r\n",
    "print(\"[INFO] training networks...\")\r\n",
    "for i in range(len(models)):\r\n",
    "    model, activation, _ = models[i]\r\n",
    "    print(f\"\\n[Info] {activation = }\")\r\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=sgd,\r\n",
    "        metrics=[\"accuracy\"])\r\n",
    "    H = model.fit(trainX, trainY, validation_data=(testX, testY),\r\n",
    "        epochs=epochs, batch_size=batch_size)\r\n",
    "    models[i] = (model, activation, H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trainingAccLoss(H):\r\n",
    "    # plot the training accuracy\r\n",
    "    plt.style.use(\"ggplot\")\r\n",
    "    plt.figure()\r\n",
    "    plt.plot(np.arange(0, epochs), H.history[\"accuracy\"], label=\"train_acc\")\r\n",
    "    plt.plot(np.arange(0, epochs), H.history[\"val_accuracy\"], label=\"val_acc\")\r\n",
    "    plt.title(\"Training Accuracy\")\r\n",
    "    plt.xlabel(\"Epoch #\")\r\n",
    "    plt.ylabel(\"Accuracy\")\r\n",
    "    plt.legend()\r\n",
    "\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    # plot the training loss\r\n",
    "\r\n",
    "    plt.plot(np.arange(0, epochs), H.history[\"loss\"], label=\"train_loss\")\r\n",
    "    plt.plot(np.arange(0, epochs), H.history[\"val_loss\"], label=\"val_loss\")\r\n",
    "    plt.title(\"Training Loss\")\r\n",
    "    plt.xlabel(\"Epoch #\")\r\n",
    "    plt.ylabel(\"Loss\")\r\n",
    "    plt.legend()\r\n",
    "\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] evaluating network...\")\r\n",
    "for model, activation, H in models:\r\n",
    "    print(f\"\\n[Info] {activation = }\")\r\n",
    "    predictions = model.predict(testX, batch_size=batch_size)\r\n",
    "    print(classification_report(testY.argmax(axis=1),\r\n",
    "\t    predictions.argmax(axis=1),\r\n",
    "\t    target_names=[str(x) for x in lb.classes_]))\r\n",
    "    plot_trainingAccLoss(H)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}