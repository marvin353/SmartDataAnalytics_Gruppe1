{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die accuracy/Genauigkeit ist eine nutzbare Metrik, solange ein ausgeglichenes Datenset zu Grunde liegt. Da die Confusion Matrix zur Validierung der Ergebnisse eingesetzt wurde und diese bestätigt, ist in diesem Fall die accuracy geeignet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meine Schlussfolgerung ist, dass mit Hilfe der Struktur der Server die ANalyse der Daten mit Tools bereichert wird und somit für die gebräuchlichsten Anwendungen eine Zeitersparnis für das Erstellen eines Analyseprogramms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das kann sein, wenn wie in a genannt die Genauigkeit keine geeignete Metrik ist.\r\n",
    "Die Verhaltensanalyse von Kunden würde in die Interpendanzanalyse fallen. Man versucht eine Gruppierung anhand der vorhanden Daten zu finden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\r\n",
    "from pandas.plotting import scatter_matrix\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn import model_selection\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.svm import SVC\r\n",
    "\r\n",
    "import os.path\r\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\r\n",
    "cwd = os.getcwd()\r\n",
    "file = os.path.join(cwd, \"Datasets\",\"Iris.csv\")\r\n",
    "names = [\"sepal-length\", \"sepal-width\", \"petal-length\", \"petal-width\", \"class\"]\r\n",
    "dataset = pandas.read_csv(file, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151, 5)\n"
     ]
    }
   ],
   "source": [
    "# shape\r\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal-length   sepal-width   petal-length   petal-width        class\n",
      "Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "1             5.1           3.5            1.4           0.2  Iris-setosa\n",
      "2             4.9           3.0            1.4           0.2  Iris-setosa\n",
      "3             4.7           3.2            1.3           0.2  Iris-setosa\n",
      "4             4.6           3.1            1.5           0.2  Iris-setosa\n",
      "5             5.0           3.6            1.4           0.2  Iris-setosa\n",
      "6             5.4           3.9            1.7           0.4  Iris-setosa\n",
      "7             4.6           3.4            1.4           0.3  Iris-setosa\n",
      "8             5.0           3.4            1.5           0.2  Iris-setosa\n",
      "9             4.4           2.9            1.4           0.2  Iris-setosa\n",
      "10            4.9           3.1            1.5           0.1  Iris-setosa\n",
      "11            5.4           3.7            1.5           0.2  Iris-setosa\n",
      "12            4.8           3.4            1.6           0.2  Iris-setosa\n",
      "13            4.8           3.0            1.4           0.1  Iris-setosa\n",
      "14            4.3           3.0            1.1           0.1  Iris-setosa\n",
      "15            5.8           4.0            1.2           0.2  Iris-setosa\n",
      "16            5.7           4.4            1.5           0.4  Iris-setosa\n",
      "17            5.4           3.9            1.3           0.4  Iris-setosa\n",
      "18            5.1           3.5            1.4           0.3  Iris-setosa\n",
      "19            5.7           3.8            1.7           0.3  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "# head\r\n",
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-10-b716d564637d>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-b716d564637d>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    dataset.plot(kind=’box’, subplots=True, layout=(2,2), sharex=False, sharey=False)\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "# box and whisker plots\r\n",
    "dataset.plot(kind=’box’, subplots=True, layout=(2,2), sharex=False, sharey=False)\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms\r\n",
    "dataset.hist()\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot matrix\r\n",
    "scatter_matrix(dataset)\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataset.values\r\n",
    "X = array[:,0:4]\r\n",
    "Y = array[:,4]\r\n",
    "validation_size = 0.20\r\n",
    "seed = 7\r\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\r\n",
    "seed = 7\r\n",
    "scoring = \"accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot Check Algorithms\r\n",
    "models = []\r\n",
    "models.append((’LR’, LogisticRegression()))\r\n",
    "models.append((’LDA’, LinearDiscriminantAnalysis()))\r\n",
    "models.append((’KNN’, KNeighborsClassifier()))\r\n",
    "models.append((’CART’, DecisionTreeClassifier()))\r\n",
    "models.append((’NB’, GaussianNB()))\r\n",
    "models.append((’SVM’, SVC()))\r\n",
    "# evaluate each model in turn\r\n",
    "results = []\r\n",
    "names = []\r\n",
    "for name, model in models:\r\n",
    "cv_results=model_selection.cross_val_score(model, X_train, Y_train, cv=10, scoring=scoring)\r\n",
    "results.append(cv_results)\r\n",
    "names.append(name)\r\n",
    "msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\r\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\r\n",
    "fig = plt.figure()\r\n",
    "fig.suptitle(’Algorithm Comparison’)\r\n",
    "ax = fig.add_subplot(111)\r\n",
    "plt.boxplot(results)\r\n",
    "ax.set_xticklabels(names)\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation dataset\r\n",
    "knn = KNeighborsClassifier()\r\n",
    "knn.fit(X_train, Y_train)\r\n",
    "predictions = knn.predict(X_validation)\r\n",
    "print(accuracy_score(Y_validation, predictions))\r\n",
    "print(confusion_matrix(Y_validation, predictions))\r\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('praktikum': conda)",
   "name": "python388jvsc74a57bd06c4bc1d378807417c9b63a056eaae59d915bab65703b0399b0b08eff1f44b459"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}